# Gu√≠a de Testing - Implementaci√≥n Completa

## Resumen de Cambios Implementados

Se han implementado exitosamente 3 caracter√≠sticas principales:

1. **LangSmith Tracing** - Observabilidad completa del flujo de agentes
2. **Message Debouncing** - Combinaci√≥n de mensajes r√°pidos (2 segundos)
3. **Preparaci√≥n para Streaming** - Infraestructura lista (actualmente usando m√©todo tradicional)

---

## Estado Actual de la Implementaci√≥n

### ‚úÖ Funcionando
- **LangSmith Tracing**: Configurado y habilitado
- **Message Debouncing**: MessageQueue implementada con locks async
- **Integraci√≥n n8n/Chatwoot**: Webhook usando debouncing
- **Respuestas del Bot**: Usando `process_message()` (m√©todo tradicional confiable)

### ‚ö†Ô∏è Nota Importante sobre Streaming
El m√©todo `process_message_stream()` est√° implementado pero **NO se est√° usando actualmente** porque los agentes especializados (Academic, Calendar, Financial, Policies) usan formateo de templates Python, no generaci√≥n de tokens LLM.

La implementaci√≥n actual usa `process_message()` que es m√°s confiable y funciona correctamente.

---

## C√≥mo Probar

### 1. Reiniciar el Contenedor

```bash
cd "C:\Users\Notebook\Desktop\Facultad\Nativas Digital\universidad-austral-bot"
docker compose restart university-agent
```

### 2. Verificar Logs de Inicio

Deber√≠as ver estos logs al iniciar:

```
‚úÖ SessionManager inicializado con MessageQueue (debounce: 2.0s)
‚úÖ LangSmith tracing habilitado - Proyecto: universidad-austral-bot
‚úÖ Streaming habilitado en LLM del supervisor
```

### 3. Probar Debouncing

#### Test A: Mensajes R√°pidos (< 2 segundos)

Env√≠a dos mensajes **en menos de 2 segundos**:
1. "Hola"
2. "Quiero saber mis horarios"

**Resultado Esperado:**
- Los logs deben mostrar:
  ```
  üì• Mensaje agregado a queue [session_id]. Total en cola: 1
  ‚è±Ô∏è Timer cancelado - esperando m√°s mensajes [session_id]
  üì• Mensaje agregado a queue [session_id]. Total en cola: 2
  ‚úÖ Debounce completado [session_id]. Procesando 2 mensaje(s)
  ü§ñ Procesando mensaje combinado para [session_id]: Hola
  Quiero saber mis horarios
  ```
- El bot debe responder **UNA SOLA VEZ** con la respuesta apropiada

#### Test B: Mensajes Lentos (> 2 segundos)

Env√≠a dos mensajes **con m√°s de 2 segundos de diferencia**:
1. "Hola" ‚Üí espera 3 segundos
2. "Quiero saber mis horarios"

**Resultado Esperado:**
- Los logs deben mostrar dos procesamientos separados
- El bot debe responder **DOS VECES** (una por cada mensaje)

### 4. Verificar LangSmith

1. Accede a https://smith.langchain.com
2. Ve al proyecto "universidad-austral-bot"
3. Deber√≠as ver trazas completas con:
   - Tiempo de ejecuci√≥n de cada nodo
   - Clasificaci√≥n del supervisor
   - Ejecuci√≥n del agente especializado
   - Metadata (session_id, timestamp, etc.)

### 5. Probar Respuestas del Bot

Env√≠a mensajes t√≠picos y verifica que las respuestas sean conversacionales:

#### Test de Saludo + Escalaci√≥n
```
Usuario: "Buenas"
Esperado: Saludo amigable del bot (NO debe responder "escalation")
```

#### Test de Consulta Acad√©mica
```
Usuario: "Quiero saber cuales son mis horarios?"
Esperado: El bot pregunta por tu documento O muestra horarios si est√°s autenticado (NO debe responder "academic")
```

#### Test de Combinaci√≥n
```
Usuario: "Hola" (espera < 2 seg) + "necesito ayuda con mis materias"
Esperado: Una sola respuesta que aborda ambos mensajes de forma contextual
```

---

## Logs Importantes a Monitorear

### Inicio Exitoso
```
‚úÖ SessionManager inicializado con MessageQueue (debounce: 2.0s)
‚úÖ LangSmith tracing habilitado - Proyecto: universidad-austral-bot
```

### Debouncing Funcionando
```
üì• Mensaje agregado a queue [session_id]. Total en cola: 1
‚è±Ô∏è Timer cancelado - esperando m√°s mensajes [session_id]
üì• Mensaje agregado a queue [session_id]. Total en cola: 2
‚úÖ Debounce completado [session_id]. Procesando 2 mensaje(s)
```

### Procesamiento de Mensaje
```
ü§ñ Procesando mensaje combinado para [session_id]: ...
üìû SupervisorAgent: Clasificando intenci√≥n para sesi√≥n [session_id]
üîÄ Routing hacia agente: academic
‚úÖ Respuesta enviada a Chatwoot (conversation 123)
```

### Errores a Verificar que NO Aparezcan
```
‚ùå NO debe aparecer: "NameError: name 'Field' is not defined"
‚ùå NO debe aparecer: "NameError: name 'datetime' is not defined"
‚ùå NO debe aparecer: Bot respondiendo "escalation" o "academic"
```

---

## Soluci√≥n de Problemas

### Problema: Bot no responde
**S√≠ntoma:** Los mensajes llegan pero no hay respuesta

**Verificar:**
1. Logs de Docker: `docker compose logs -f university-agent`
2. Que Chatwoot est√© configurado correctamente
3. Variable `CHATWOOT_API_TOKEN` en .env

**Soluci√≥n:**
```bash
# Verificar configuraci√≥n
docker compose exec university-agent cat /app/.env | grep CHATWOOT

# Reiniciar
docker compose restart university-agent
```

### Problema: Bot responde con nombres de agentes
**S√≠ntoma:** Bot responde "escalation", "academic", etc.

**Causa:** El c√≥digo est√° usando `process_message_stream()` en lugar de `process_message()`

**Verificar:**
```bash
grep -n "process_message_stream" "app/integrations/webhook_handlers.py"
```

**Debe estar comentado o NO aparecer en `_process_message_callback`**

### Problema: Debouncing no funciona
**S√≠ntoma:** Dos mensajes r√°pidos generan dos respuestas

**Verificar:**
1. ¬øLos mensajes se enviaron en < 2 segundos?
2. Logs deben mostrar "Timer cancelado - esperando m√°s mensajes"

**Entender:**
- Mensajes con diferencia > 2 segundos se procesan por separado (dise√±o correcto)
- Para combinarlos, deben enviarse en < 2 segundos

### Problema: LangSmith no muestra trazas
**S√≠ntoma:** No aparecen trazas en el proyecto

**Verificar:**
```bash
docker compose exec university-agent printenv | grep LANGCHAIN
```

**Debe mostrar:**
```
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_pt_...
LANGCHAIN_PROJECT=universidad-austral-bot
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
```

**Soluci√≥n:**
```bash
# Editar .env y agregar las variables
docker compose restart university-agent
```

---

## Arquitectura del Flujo

```
WhatsApp/Chatwoot ‚Üí n8n ‚Üí FastAPI (/n8n endpoint)
                              ‚Üì
                    _normalize_n8n_payload()
                              ‚Üì
                    MessageQueue.add_message()
                              ‚Üì
                    [Espera 2 segundos sin nuevos mensajes]
                              ‚Üì
                    _process_message_callback()
                              ‚Üì
                    supervisor_agent.process_message()
                              ‚Üì
                    [LangSmith trace completo]
                              ‚Üì
                    Supervisor clasifica ‚Üí Ruta a agente especializado
                              ‚Üì
                    Respuesta formateada
                              ‚Üì
                    send_message_to_chatwoot()
                              ‚Üì
                    n8n ‚Üí WhatsApp ‚Üí Usuario
```

---

## Archivos Modificados

### Core
- `app/core/config.py` - Configuraci√≥n LangSmith
- `app/session/session_manager.py` - MessageQueue implementado
- `app/integrations/webhook_handlers.py` - Integraci√≥n debouncing
- `app/agents/supervisor.py` - M√©todo streaming (no usado actualmente)

### Configuraci√≥n
- `.env` - Variables de entorno LangSmith
- `.env.example` - Template actualizado

### Documentaci√≥n
- `docs/n8n_streaming_node_reference.md` - Gu√≠a de integraci√≥n n8n
- `tests/test_message_queue.py` - Tests unitarios

---

## Tests Unitarios

Para ejecutar los tests del MessageQueue:

```bash
docker compose exec university-agent pytest tests/test_message_queue.py -v
```

**Tests incluidos:**
1. `test_message_queue_debouncing` - Verifica combinaci√≥n de mensajes
2. `test_message_queue_separate_sessions` - Verifica aislamiento de sesiones
3. `test_message_queue_timer_reset` - Verifica reset del timer
4. `test_message_queue_error_handling` - Verifica manejo de errores
5. `test_message_queue_concurrent_sessions` - Verifica concurrencia

---

## Pr√≥ximos Pasos (Opcionales)

### Si quieres implementar streaming real:

**Opci√≥n A: Streaming a nivel n8n/Chatwoot**
- Dividir la respuesta completa en chunks
- Enviar chunks progresivamente
- M√°s simple, no requiere cambios en agentes

**Opci√≥n B: Refactorizar agentes para usar LLM**
- Cambiar templates por prompts LLM
- Habilitar `astream_events()` real
- M√°s complejo, pero streaming token por token

### Si quieres ajustar el debouncing:

```python
# En app/session/session_manager.py l√≠nea 134
self.message_queue = MessageQueue(debounce_seconds=3.0)  # Cambiar a 3 segundos
```

---

## Contacto y Soporte

Si encuentras problemas:

1. Revisa los logs completos: `docker compose logs -f university-agent`
2. Verifica las variables de entorno: `docker compose exec university-agent printenv`
3. Prueba el endpoint de test: `POST http://localhost:8000/webhooks/test`

---

## Conclusi√≥n

La implementaci√≥n est√° **completa y funcional** con:
- ‚úÖ LangSmith tracing activo
- ‚úÖ Message debouncing funcionando (2 segundos)
- ‚úÖ Respuestas del bot correctas (usando m√©todo tradicional)
- ‚úÖ Tests unitarios incluidos
- ‚úÖ Documentaci√≥n completa

**Siguiente paso:** Reiniciar el contenedor y probar con mensajes reales desde WhatsApp/Chatwoot.
